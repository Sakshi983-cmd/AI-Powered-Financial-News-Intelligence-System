"""
Query Processing Agent - Context-aware intelligent querying
"""
from typing import Dict, List
from database.vector_store import VectorStore
from database.knowledge_graph import FinancialKnowledgeGraph
from agents.entity_extraction_agent import EntityExtractionAgent
from utils.logger import logger

class QueryProcessingAgent:
    """
    Agent 6: Process natural language queries with context expansion
    This makes your system INTELLIGENT!
    """
    
    def __init__(self, vector_store: VectorStore, knowledge_graph: FinancialKnowledgeGraph):
        self.vector_store = vector_store
        self.kg = knowledge_graph
        self.entity_extractor = EntityExtractionAgent()
    
    def process(self, query: str, top_k: int = 10, explain: bool = True) -> Dict:
        """
        Process user query with context expansion
        """
        try:
            logger.info(f"ðŸ” Processing query: {query}")
            
            # Step 1: Extract entities from query
            query_entities = self._extract_query_entities(query)
            logger.info(f"  Extracted entities: {query_entities}")
            
            # Step 2: Expand context using Knowledge Graph
            expanded_entities = self._expand_context(query_entities)
            logger.info(f"  Expanded to: {len(expanded_entities)} entities")
            
            # Step 3: Hybrid search (semantic + entity matching)
            results = self.vector_store.hybrid_search(
                query=query,
                entities=expanded_entities,
                top_k=top_k * 2  # Get more, then re-rank
            )
            
            # Step 4: Re-rank results
            ranked_results = self._rerank_results(results, query, query_entities, expanded_entities)
            
            # Step 5: Add explanations if requested
            if explain:
                ranked_results = self._add_explanations(ranked_results, query, query_entities)
            
            logger.info(f"âœ“ Found {len(ranked_results)} relevant articles")
            
            return {
                'query': query,
                'results': ranked_results[:top_k],
                'total_found': len(ranked_results),
                'query_entities': query_entities,
                'expanded_entities': expanded_entities
            }
            
        except Exception as e:
            logger.error(f"Error processing query: {e}")
            return {
                'query': query,
                'results': [],
                'total_found': 0,
                'error': str(e)
            }
    
    def _extract_query_entities(self, query: str) -> Dict:
        """Extract entities from user query"""
        # Use entity extractor
        fake_article = {
            'title': query,
            'content': '',
            'id': 'query'
        }
        
        processed = self.entity_extractor.process(fake_article)
        return processed['entities']
    
    def _expand_context(self, entities: Dict) -> List[str]:
        """
        Expand entities using Knowledge Graph
        This is KEY for context-aware queries!
        """
        expanded = set()
        
        # Add original entities
        for entity_type in ['companies', 'sectors', 'regulators']:
            expanded.update(entities.get(entity_type, []))
        
        # Expand companies â†’ sectors
        for company in entities.get('companies', []):
            if company in self.kg.graph:
                impacted = self.kg.get_impacted_entities(company, max_depth=2)
                expanded.update(impacted.keys())
        
        # Expand sectors â†’ companies
        for sector in entities.get('sectors', []):
            if sector in self.kg.graph:
                companies = self.kg.get_companies_in_sector(sector)
                expanded.update(companies)
                
                # Also add related sectors
                impacted = self.kg.get_impacted_entities(sector, max_depth=1)
                expanded.update(impacted.keys())
        
        # Expand regulators â†’ affected entities
        for regulator in entities.get('regulators', []):
            if regulator in self.kg.graph:
                impacted = self.kg.get_impacted_entities(regulator, max_depth=2)
                expanded.update(impacted.keys())
        
        return list(expanded)
    
    def _rerank_results(self, results: List[Dict], query: str, 
                       query_entities: Dict, expanded_entities: List[str]) -> List[Dict]:
        """
        Re-rank results based on multiple factors
        """
        for result in results:
            score_components = {
                'semantic': result.get('combined_score', result.get('similarity', 0)),
                'entity_match': 0,
                'recency': 0,
                'sentiment_relevance': 0
            }
            
            # Entity matching bonus
            result_entities_str = result['metadata'].get('entities', '[]')
            try:
                result_entities = eval(result_entities_str) if isinstance(result_entities_str, str) else result_entities_str
            except:
                result_entities = []
            
            if isinstance(result_entities, dict):
                all_result_entities = []
                for ent_list in result_entities.values():
                    if isinstance(ent_list, list):
                        all_result_entities.extend(ent_list)
            else:
                all_result_entities = result_entities if isinstance(result_entities, list) else []
            
            # Calculate entity overlap
            query_ent_flat = []
            for ent_list in query_entities.values():
                if isinstance(ent_list, list):
                    query_ent_flat.extend(ent_list)
            
            overlap = len(set(query_ent_flat) & set(all_result_entities))
            score_components['entity_match'] = overlap / max(len(query_ent_flat), 1)
            
            # Final score (weighted combination)
            result['final_score'] = (
                0.5 * score_components['semantic'] +
                0.3 * score_components['entity_match'] +
                0.2 * score_components.get('recency', 0)
            )
            
            result['score_breakdown'] = score_components
        
        # Sort by final score
        results.sort(key=lambda x: x['final_score'], reverse=True)
        
        return results
    
    def _add_explanations(self, results: List[Dict], query: str, 
                         query_entities: Dict) -> List[Dict]:
        """
        Add explanations for why each result was retrieved
        EXPLAINABILITY FEATURE - Judges love this!
        """
        for result in results:
            explanation_parts = []
            
            # Semantic match
            if result.get('similarity', 0) > 0.7:
                explanation_parts.append(
                    f"High semantic similarity ({result['similarity']:.2f})"
                )
            
            # Entity matches
            score_breakdown = result.get('score_breakdown', {})
            if score_breakdown.get('entity_match', 0) > 0.5:
                explanation_parts.append(
                    f"Strong entity match ({score_breakdown['entity_match']:.2f})"
                )
            
            # Knowledge graph reasoning
            result_entities_str = result['metadata'].get('entities', '{}')
            try:
                result_entities = eval(result_entities_str) if isinstance(result_entities_str, str) else result_entities_str
            except:
                result_entities = {}
            
            if isinstance(result_entities, dict):
                result_companies = result_entities.get('companies', [])
                query_companies = query_entities.get('companies', [])
                
                for q_comp in query_companies:
                    for r_comp in result_companies:
                        if q_comp in self.kg.graph and r_comp in self.kg.graph:
                            paths = self.kg.explain_relationship(q_comp, r_comp)
                            if paths:
                                explanation_parts.append(f"Related via: {paths[0]}")
                                break
            
            result['explanation'] = " | ".join(explanation_parts) if explanation_parts else "Semantic match"
        
        return results
    
    def get_query_suggestions(self, partial_query: str) -> List[str]:
        """Suggest completions for partial queries"""
        # This would use your entity dictionaries
        suggestions = []
        
        # Check companies
        for company in self.entity_extractor.companies:
            if partial_query.lower() in company.lower():
                suggestions.append(f"{company} news")
        
        # Check sectors
        for sector in self.entity_extractor.sectors:
            if partial_query.lower() in sector.lower():
                suggestions.append(f"{sector} sector update")
        
        return suggestions[:5]