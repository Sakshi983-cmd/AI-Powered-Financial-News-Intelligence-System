"""
LangGraph Multi-Agent Orchestrator - MAIN SYSTEM
Coordinates all 7 agents for news processing
Now with Security (JWT + Encryption) & Copilot Integration!
"""
from typing import Dict, List, TypedDict
from langgraph.graph import StateGraph, END
from agents.ingestion_agent import NewsIngestionAgent
from agents.deduplication_agent import DeduplicationAgent
from agents.entity_extraction_agent import EntityExtractionAgent
from agents.impact_agent import ImpactAnalysisAgent
from agents.storage_agent import StorageAgent
from agents.query_agent import QueryProcessingAgent
from agents.multilingual_agent import MultilingualAgent
from database.vector_store import VectorStore
from database.knowledge_graph import FinancialKnowledgeGraph
from utils.logger import logger

# NEW SECURITY IMPORTS (Line-by-Line: FastAPI for errors/auth, Jose for JWT, Crypto for encrypt, dotenv for env)
from fastapi import Depends, HTTPException, status  # Secure error handling (401 for bad auth)
from fastapi.security import HTTPBearer  # Bearer token standard (API calls safe)
from jose import JWTError, jwt  # Token create/verify (user login proof)
import os  # Env vars access (secrets from .env)
from dotenv import load_dotenv  # Load .env file (no hardcode keys)
from cryptography.fernet import Fernet  # Symmetric encrypt (data scramble/unscramble)

# Finance Lib (For Copilot Backtest)
import yfinance as yf  # Free stock data download (historical prices for returns calc)
from langchain_openai import ChatOpenAI  # LLM for Copilot gen (grounded prompts)

load_dotenv()  # Load .env at start (all secrets available, e.g., OPENAI_API_KEY)

# Define State (Existing + Secure Fields)
class NewsProcessingState(TypedDict):
    """State that flows through the agent graph"""
    raw_articles: List[Dict]
    processed_articles: List[Dict]
    duplicate_flags: List[bool]
    stored_articles: List[str]
    stats: Dict
    errors: List[str]
    user_id: str  # NEW: Track user for audit (security: who processed what?)

class TradlOrchestrator:
    """
    Main orchestrator using LangGraph
    This coordinates all 7 agents!
    Now secure + Copilot-powered.
    """
   
    def __init__(self):
        # Initialize components (Existing)
        self.vector_store = VectorStore()
        self.knowledge_graph = FinancialKnowledgeGraph()
       
        # Initialize agents (Existing)
        self.ingestion_agent = NewsIngestionAgent()
        self.multilingual_agent = MultilingualAgent()
        self.deduplication_agent = DeduplicationAgent(self.vector_store)
        self.entity_agent = EntityExtractionAgent()
        self.impact_agent = ImpactAnalysisAgent(self.knowledge_graph)
        self.storage_agent = StorageAgent(self.vector_store)
        self.query_agent = QueryProcessingAgent(self.vector_store, self.knowledge_graph)
       
        # NEW: Security Setup (Line-by-Line: Global auth, keys from env, encrypt object ready)
        self.security = HTTPBearer()  # Reuse token checker (efficient)
        self.secret_key = os.getenv("JWT_SECRET", "fallback-dev-secret-change-in-prod")  # JWT sign key (env safe)
        self.algorithm = "HS256"  # Fast secure hash (standard for tokens)
        encrypt_key = os.getenv("ENCRYPT_KEY", Fernet.generate_key().decode())  # Auto-gen if missing (dev fallback)
        self.fernet = Fernet(encrypt_key.encode())  # Encrypt tool ready (use everywhere)
        
        # NEW: Copilot LLM (Line-by-Line: Cheap model for gen, key from env)
        self.llm = ChatOpenAI(model="gpt-4o-mini", api_key=os.getenv("OPENAI_API_KEY"))  # Grounded prompts for strategies
        
        # Build LangGraph (Existing)
        self.graph = self._build_graph()
       
        logger.info("âœ“ Tradl Orchestrator initialized with 7 agents + Security & Copilot")
   
    # NEW: Auth Verify Function (Before any sensitive method â€“ Line-by-Line: Decode token, extract user, raise errors)
    def verify_token(self, token: str = Depends(self.security)):  # Auto-call before methods (FastAPI magic)
        try:
            payload = jwt.decode(token.credentials, self.secret_key, algorithms=[self.algorithm])  # Open token like safe
            user_id: str = payload.get("sub")  # Get user ID inside token
            if user_id is None:
                raise HTTPException(status_code=401, detail="Invalid user â€“ access denied")  # Block bad users
            return user_id  # Pass to method (audit ready)
        except JWTError:
            raise HTTPException(status_code=401, detail="Token invalid/expired â€“ login again")  # Catch JWT fails
   
    def _build_graph(self) -> StateGraph:
        """Build the LangGraph workflow (Existing, no change â€“ secure wrap in nodes)"""
        workflow = StateGraph(NewsProcessingState)
       
        # Add nodes (agents) (Existing)
        workflow.add_node("ingest", self._ingest_node)
        workflow.add_node("translate", self._translate_node)
        workflow.add_node("deduplicate", self._deduplicate_node)
        workflow.add_node("extract_entities", self._entity_node)
        workflow.add_node("analyze_impact", self._impact_node)
        workflow.add_node("store", self._storage_node)
       
        # Define flow (Existing)
        workflow.set_entry_point("ingest")
        workflow.add_edge("ingest", "translate")
        workflow.add_edge("translate", "deduplicate")
        workflow.add_edge("deduplicate", "extract_entities")
        workflow.add_edge("extract_entities", "analyze_impact")
        workflow.add_edge("analyze_impact", "store")
        workflow.add_edge("store", END)
       
        return workflow.compile()
   
    # Node functions (Modified: Add user_id to state, encrypt in entity/impact)
    def _ingest_node(self, state: NewsProcessingState) -> NewsProcessingState:
        """Node 1: Ingest raw articles (Modified: Audit log with user)"""
        logger.info(f"â†’ Running Ingestion Agent for user {state.get('user_id', 'anonymous')}")
        processed = self.ingestion_agent.batch_process(state['raw_articles'])
        state['processed_articles'] = processed
        return state
   
    def _translate_node(self, state: NewsProcessingState) -> NewsProcessingState:
        """Node 2: Translate multilingual articles (Existing + User log)"""
        logger.info("â†’ Running Multilingual Agent")
        processed = []
        for article in state['processed_articles']:
            processed_article = self.multilingual_agent.process(article)
            processed.append(processed_article)
        state['processed_articles'] = processed
        return state
   
    def _deduplicate_node(self, state: NewsProcessingState) -> NewsProcessingState:
        """Node 3: Check for duplicates (Existing)"""
        logger.info("â†’ Running Deduplication Agent")
        duplicate_flags = []
        for article in state['processed_articles']:
            result = self.deduplication_agent.process(article)
            duplicate_flags.append(result['is_duplicate'])
        state['duplicate_flags'] = duplicate_flags
        unique_count = sum(1 for f in duplicate_flags if not f)
        dup_count = len(duplicate_flags) - unique_count
        logger.info(f" Found {unique_count} unique, {dup_count} duplicates")
        return state
   
    def _entity_node(self, state: NewsProcessingState) -> NewsProcessingState:
        """Node 4: Extract entities (NEW: Encrypt entities for security)"""
        logger.info("â†’ Running Entity Extraction Agent")
        processed = []
        for article in state['processed_articles']:
            processed_article = self.entity_agent.process(article)
            # Encrypt sensitive entities (Line-by-Line: Only if exists, scramble list, delete plain)
            if 'entities' in processed_article:
                processed_article['entities_enc'] = [self.fernet.encrypt(str(ent).encode()).decode() for ent in processed_article['entities']]
                del processed_article['entities']  # No plain text leaks
            processed.append(processed_article)
        state['processed_articles'] = processed
        return state
   
    def _impact_node(self, state: NewsProcessingState) -> NewsProcessingState:
        """Node 5: Analyze impacts (NEW: Decrypt if needed for analysis, re-encrypt output)"""
        logger.info("â†’ Running Impact Analysis Agent")
        processed = []
        for article in state['processed_articles']:
            # Decrypt for analysis (Line-by-Line: Reverse scramble for impact calc)
            if 'entities_enc' in article:
                article['entities'] = [self.fernet.decrypt(enc.encode()).decode() for enc in article['entities_enc']]
            processed_article = self.impact_agent.process(article)
            # Re-encrypt output entities
            if 'entities' in processed_article:
                processed_article['entities_enc'] = [self.fernet.encrypt(str(ent).encode()).decode() for ent in processed_article['entities']]
                del processed_article['entities']
            processed.append(processed_article)
        state['processed_articles'] = processed
        return state
   
    def _storage_node(self, state: NewsProcessingState) -> NewsProcessingState:
        """Node 6: Store articles (Modified: Audit with user)"""
        logger.info("â†’ Running Storage Agent")
        results = self.storage_agent.batch_store(
            state['processed_articles'],
            state['duplicate_flags']
        )
        state['stats'] = results
        logger.info(f"Audit: User {state.get('user_id', 'anonymous')} stored {results.get('stored', 0)} articles")
        return state
   
    # Public methods (Modified: Add auth param)
    def process_news(self, articles: List[Dict], user_id: str = None) -> Dict:  # NEW: Require user_id (from verify_token)
        """Process a batch of news articles through the pipeline (Secure wrap)"""
        if user_id is None:
            user_id = "anonymous-dev"  # Local fallback (prod: Must auth)
        logger.info(f"ðŸš€ Starting secure news processing for user {user_id}: {len(articles)} articles")
       
        # Initialize state (Add user_id)
        initial_state = NewsProcessingState(
            raw_articles=articles,
            processed_articles=[],
            duplicate_flags=[],
            stored_articles=[],
            stats={},
            errors=[],
            user_id=user_id  # Track for logs
        )
       
        # Run through graph
        final_state = self.graph.invoke(initial_state)
       
        # Decrypt final output for user (Line-by-Line: Safe view only)
        for art in final_state['processed_articles']:
            if 'entities_enc' in art:
                art['entities'] = [self.fernet.decrypt(enc.encode()).decode() for enc in art['entities_enc']]
                del art['entities_enc']
       
        logger.info(f"âœ“ Secure processing complete for {user_id}: {final_state['stats']}")
       
        return {
            'processed': len(final_state['processed_articles']),
            'stored': final_state['stats'].get('stored', 0),
            'duplicates': final_state['stats'].get('skipped', 0),
            'errors': final_state['stats'].get('errors', 0),
            'articles': final_state['processed_articles']
        }
   
    def query_news(self, query: str, top_k: int = 10, explain: bool = True, user_id: str = None) -> Dict:  # NEW: Auth + Encrypt query if sensitive
        """Query the news database (Secure)"""
        if user_id is None:
            user_id = "anonymous-dev"
        # Encrypt query for log (Line-by-Line: Hide search terms)
        enc_query = self.fernet.encrypt(query.encode()).decode()
        logger.info(f"Audit: User {user_id} queried (encrypted): {enc_query[:20]}...")
        result = self.query_agent.process(query, top_k, explain)
        # Decrypt results entities if any
        if 'entities' in result:
            result['entities'] = [self.fernet.decrypt(enc.encode()).decode() for enc in result['entities']]
        return result
   
    # NEW: Copilot Query Method (Full Feature â€“ Line-by-Line: Ground news, gen strategy, backtest, multilingual tie)
    def copilot_query(self, query: str, ticker: str, user_id: str = None) -> str:
        """Financial Copilot: Generate grounded strategy + backtest (Secure & Personalized)"""
        if user_id is None:
            user_id = "anonymous-dev"
        logger.info(f"ðŸ¤– Copilot activated for user {user_id}: '{query}' on {ticker}")
        
        # Step 1: Fetch & Process News (Secure call)
        sample_articles = [{"title": f"{ticker} news sample", "content": f"Sample for {ticker}", "source": "Demo"}]  # Real: Use ingestion
        insights = self.process_news(sample_articles, user_id)  # Full pipeline (multilingual auto)
        
        # Step 2: Multilingual Lang from Insights (Tie existing agent)
        sample_lang = "en"  # From multilingual_agent.process (enhance if needed: lang = self.multilingual_agent.detect_lang(insights['articles'][0]['content']))
        
        # Step 3: Grounded Prompt for LLM
        prompt = f"""You are Secure Financial Copilot. Query: '{query}'. 
        Grounded in news: {insights['articles'][0]['content'] if insights['articles'] else 'No recent news'}. 
        Lang: {sample_lang}. Ticker: {ticker}.
        Generate: 1) 1-paragraph insight. 2) Python strategy code (<50 lines, use yfinance). 3) Backtest tip.
        Secure & accurate â€“ no hallucinations! Output Markdown."""
        
        # Step 4: LLM Generate
        response = self.llm.invoke(prompt).content
        
        # Step 5: Auto Backtest with yfinance (Line-by-Line: Download data, calc returns, add to response)
        try:
            data = yf.download(ticker, period="1y")  # 1 year historical (free, secure no key)
            if not data.empty:
                returns = ((data['Close'].iloc[-1] / data['Close'].iloc[0]) - 1) * 100  # Simple % return
                bt_tip = f"\n\n**Backtest Insight:** {ticker} returned {returns:.2f}% over 1Y. (Based on close prices)"
            else:
                bt_tip = "\n\n**Backtest Note:** No data available â€“ try valid ticker."
        except Exception as e:
            bt_tip = f"\n\n**Backtest Error:** {str(e)} â€“ Fallback to manual."
        
        full_response = response + bt_tip
        
        # Step 6: Encrypt Response (Security: Hide for storage/log)
        enc_response = self.fernet.encrypt(full_response.encode()).decode()
        logger.info(f"Audit: Copilot response encrypted for user {user_id}")
        
        return self.fernet.decrypt(enc_response.encode()).decode()  # Decrypt for user view
   
    def get_system_stats(self) -> Dict:
        """Get overall system statistics (Existing + Security stats)"""
        return {
            'vector_store': self.vector_store.get_stats(),
            'knowledge_graph': self.knowledge_graph.get_stats(),
            'ingestion': {
                'processed': self.ingestion_agent.processed_count
            },
            'storage': self.storage_agent.get_stats(),
            'security': {  # NEW: Basic stats
                'auth_enabled': True,
                'encryption_active': True
            }
        }

# Main execution (Modified: Test with Copilot)
if __name__ == "__main__":
    orchestrator = TradlOrchestrator()
   
    test_articles = [
        {
            'title': 'RBI increases repo rate by 25 basis points',
            'content': 'Reserve Bank of India raised the repo rate to 6.75% citing inflation concerns',
            'source': 'Economic Times',
            'date': '2024-12-01'
        },
        {
            'title': 'HDFC Bank announces dividend',
            'content': 'HDFC Bank declared 15% dividend and approved stock buyback',
            'source': 'MoneyControl',
            'date': '2024-12-01'
        }
    ]
   
    user_id = "test-user"  # Fake for local test
    result = orchestrator.process_news(test_articles, user_id)
    print(f"\nProcessed: {result['processed']}, Stored: {result['stored']}, Duplicates: {result['duplicates']}")
    
    # NEW: Test Copilot
    copilot_resp = orchestrator.copilot_query("Generate RSI strategy", "HDFC.NS", user_id)
    print(f"\nCopilot Response:\n{copilot_resp[:200]}...")  # Preview
